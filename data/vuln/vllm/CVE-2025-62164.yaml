info:
  name: vllm
  cve: CVE-2025-62164
  summary: vLLM 反序列化漏洞导致拒绝服务和潜在的远程代码执行。
  details: |
    vLLM 0.10.2 及更高版本中存在内存损坏漏洞，特别是在 Completions API 端点中。
    在处理用户提供的提示嵌入时，该端点在没有充分验证的情况下使用 `torch.load()` 加载序列化张量。
    由于 PyTorch 2.8.0 的更改，稀疏张量完整性检查默认禁用，这允许恶意构造的张量绕过内部边界检查。
    这可能在调用 `to_dense()` 期间触发越界内存写入，导致托管 vLLM 的服务器崩溃（拒绝服务）并可能导致远程代码执行 (RCE)。
  cvss: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H
  severity: HIGH
  security_advise: |
    1. 将 vLLM 升级到 0.11.1 或更高版本。
    2. 在加载用户提供的张量时，对稀疏张量实施显式有效性检查，可使用 `torch.sparse.check_sparse_tensor_invariants` 上下文管理器。
  references:
    - https://github.com/vllm-project/vllm/security/advisories/GHSA-mrw7-hf4f-83pf
    - https://nvd.nist.gov/vuln/detail/CVE-2025-62164
    - https://github.com/vllm-project/vllm/pull/27204
    - https://github.com/vllm-project/vllm/commit/58fab50d82838d5014f4a14d991fdb9352c9c84b
    - https://github.com/vllm-project/vllm
rule: version >= "0.10.2" && version < "0.11.1"