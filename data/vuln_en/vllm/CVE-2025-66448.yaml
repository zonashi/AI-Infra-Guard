info:
  name: vllm
  cve: CVE-2025-66448
  summary: vLLM is vulnerable to remote code execution via `transformers_utils/get_config` due to improper handling of `auto_map` entries.
  details: |
    The `vllm` library contains a critical remote code execution vulnerability within the `Nemotron_Nano_VL_Config` class. When loading a model configuration with an `auto_map` entry, the `get_class_from_dynamic_module(...)` function resolves and immediately instantiates the referenced class. This process fetches and executes Python code from a remote repository specified in the `auto_map` string, even when `trust_remote_code=False` is explicitly set. An attacker can craft a benign-looking frontend repository whose `config.json` points to a malicious backend repository via `auto_map`, leading to silent code execution on the victim's host when the frontend model is loaded.
  cvss: CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:H/A:H
  severity: HIGH
  security_advise: |
    1. Upgrade vllm to version 0.11.1 or later.
    2. Review and validate all model configurations, especially those with `auto_map` entries, to ensure they do not point to untrusted remote repositories.
    3. Exercise caution when loading models from unknown or untrusted sources.
rule: version > "0" && version < "0.11.1"
references:
  - https://github.com/vllm-project/vllm/security/advisories/GHSA-8fr4-5q9j-m8gm
  - https://nvd.nist.gov/vuln/detail/CVE-2025-66448
  - https://github.com/vllm-project/vllm/pull/28126
  - https://github.com/vllm-project/vllm/commit/ffb08379d8870a1a81ba82b72797f196838d0c86
  - https://github.com/vllm-project/vllm