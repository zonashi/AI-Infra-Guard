info:
  name: langchain
  cve: CVE-2025-65106
  summary: LangChain is vulnerable to template injection via attribute access in prompt templates, allowing attackers to access Python object internals.
  details: |
    A template injection vulnerability exists in LangChain's prompt template system, enabling attackers to access Python object internals through template syntax. This affects applications accepting untrusted template strings in `ChatPromptTemplate` and related classes. Attackers can traverse object attributes and dictionary lookups (e.g., `__globals__`) to extract sensitive data like environment variables. The vulnerability requires control over template strings, not just template variables. Affected components include `langchain-core` and F-string, Mustache, and Jinja2 template formats.
  cvss: CVSS:4.0/AV:N/AC:L/AT:P/PR:N/UI:N/VC:H/VI:L/VA:N/SC:N/SI:N/SA:N
  severity: HIGH
  security_advise: |
    1. Audit your code for any locations where template strings originate from untrusted sources.
    2. Update to the patched version of `langchain-core` (>=1.0.7 or >=0.3.80).
    3. Review template usage to ensure a clear separation between template structure and user-provided data.
    4. Consider if templates are necessary; many applications can work directly with message objects without templates.
    5. Reserve Jinja2 templates for trusted sources only due to the difficulty of comprehensive sandboxing.
rule: (version > "0" && version < "0.3.80") || (version >= "1.0.0" && version < "1.0.7")
references:
  - https://github.com/langchain-ai/langchain/security/advisories/GHSA-6qv9-48xg-fc7f
  - https://nvd.nist.gov/vuln/detail/CVE-2025-65106
  - https://github.com/langchain-ai/langchain/commit/c4b6ba254e1a49ed91f2e268e6484011c540542a
  - https://github.com/langchain-ai/langchain/commit/fa7789d6c21222b85211755d822ef698d3b34e00
  - https://github.com/langchain-ai/langchain